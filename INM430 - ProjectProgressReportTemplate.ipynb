{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INM430 - Tiny DS Project Progress Report\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "** Student Name: Alexandros Dimitrios Nalmpantis\n",
    "\n",
    "** Project Title:SME hospitality business investment support utilising yelp and demographic data\n",
    "\n",
    "***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Progress Report - Initial Investigation\n",
    "## Part-1: Data source and domain description (maximum 150 words):\n",
    "The small business enterprise domain has been facing many risks and challenges. There are very small survival rates of small hospitality businesses in London due to the high costs related. But on this study the focus is on identifying and possibly demystifying a common phrase: \n",
    "\n",
    "*\" This is what make a successful restaurant: Location, Location, and Location\"*.\n",
    "\n",
    "**Analytical questions:**\n",
    "\n",
    "* What are the most common demographics of people in each area and are they related to the quality of the restaurants in that area?\n",
    "\n",
    "* What is the best strategy: a central area with high risk potential but high profit potential or a non central area with specific clientele?\n",
    "\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* The aim of this study is to address those issues and find the optimum location suggestions in London in terms of costs and potential profits.\n",
    "\n",
    "\n",
    "Yelp data were sourced from the API of Yelp and include business overview along with scoring and total reviews. The London data store provides demographic data along with business statistical information in London.\n",
    "\n",
    "\n",
    "## Part-2: Analysis Strategy and Plans (maximum 200 words):\n",
    "\n",
    "**1. Data wrangling:**\n",
    "\n",
    "The data were downloaded utilizing an iterative algorithm from Yelp Api with the below algorithm.\n",
    "Unfortunately yelp doesn’t allow to offset the response for more than 1000 data points thus it terminates.\n",
    "In order to overcome the yelp restrictions on data download from their API the search algorithm had to be adjusted.\n",
    "In order to divide London intro searchable chunks of data an geospatial method was utilized. London areas were downloaded as shapefiles from London Store:  https://data.london.gov.uk/dataset/statistical-gis-boundary-files-london\n",
    "\n",
    "These were imported into ArcGis and an initial centroid of each shape/areas were calculated as WGS1984 Longitude and Latitude coordinates. Those centroids are calculated as the mean from each point on the shapefile.\n",
    "Then each shape/areas was enclosed in a rectangle and the length and width was calculated. The database was then extracted and the diagonal and the radius of the rectangle was calculated utilizing the code below.\n",
    "\n",
    "<img src=\"files/Picture1.png\">\n",
    "\n",
    "Then an iterative code is utilized to call yelp api and search according to the parameters calculated.\n",
    "\n",
    "**2. Data Analysis:**\n",
    "\n",
    "On this step the database of restaurant businesses in London along with other demographic datasets will be combined.\n",
    "Datasets such as business survivability and population demographics will be utilized to check various correlations.\n",
    "Correlations such as business survivability with population income per area will be examined. \n",
    "\n",
    "Then correlations such as average review scores or restaurants and number of reviews will be utilized as qualitative and quantitative variables for finding best locations for investing into hospitality business.\n",
    "\n",
    "The tools that will be potentially used are Python, Tableau and ArcGIS.\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "## Part-3: Initial investigations on the data sources (maximum 150 words): \n",
    "\n",
    "The data that were extracted from the iterative algorithm were over 40k rows. After converting to a panda data frame so that we can modify those a total of 45k rows were found. (See cell 14 for the code and results). After removing the duplicates by utilizing the unique URL for each business a total of 14k restaurants were found. \n",
    "\n",
    "Next, the first two columns were dropped since those were unnecessary to the analysis. Then the completeness of the each variable was calculated. The Rating and review variables appear at 100% while price that will be utilized is at 63%. \n",
    "\n",
    "Finally, some descriptive statistics were calculated. For example the mean rating for restaurants in London is 3.5 stars out of 5 and an average rating count is 10.\n",
    "***\n",
    "***\n",
    "# 2: Progress continuous - Work Diary : \n",
    "\n",
    "**Following the initial data wrangling process the following followed**\n",
    "\n",
    "**1.Adding georeferences**\n",
    "*Utilising ARC-GIS the data were spatially joined with the london areas shapefiles. This process required the conversion of the cartesian coordinates to the required national grid coordinate system since London Wards shapefile is on this system. After conversion the points and shapes were displayed on the same frame and was spatially joined on point to polygon process utilising the data management techniques. Arc-Gis tool was selected for this proccess due to the availiability and quick conversion and join tools. Same process was attempted on Python with GeoPandas but even installing those tools was challenging since the dependencies are not all availiable for Python.\n",
    "\n",
    "*The proccess has created several junk columns which will be removed in the data wrangling process. This step was done in order to get the official area code id to utilise it as join unique ID with various London Data store databases.\n",
    "\n",
    "<img src=\"files/Business Map.jpg\">\n",
    "\n",
    "\n",
    "**2.Data Wrangling**\n",
    "*Apart from the initial wrangling above extensinve wrangling took place post data gathering. The initial database was in Json thus transforming this database into .csv to import in pandas has been a challenge. The pandas normalisation procedure has distributed certain nested json sections into multiple columns. For example the address has been seperated into multiple columns. Those multiple columns were concatenated into one column apart from zipcode wich will be used for data validation of the area. \n",
    "\n",
    "*Other data wrangling procedures that took place involved the dropping of columns from the two databases (Yelp and London Postcode Directory). In addition to dropping columns empty columns were also droped. For exaple data rows without an area mean that those will be located outside the polygon ward area and thus would not have been assigned an area code. Thus those businesses were droped. Other rows dropped were regarding for example no data on postcode or rating and reviews.\n",
    "\n",
    "*Further data wrangling process has taken place on the category labels. These labels were nested from the json conversion and thus remained in one column. Some initial investigation on the row dat ahas revealed that the first nested column of alias and title is the main category of the data/restaurants. For example the restaurants are labeled according to the cuisine offering and the fastfoods as fastfoods. Thus those data were seperated by replacing and spliting characters to reach the desired two columns of Alias and Title. The main category label was reserved in case we need to dive deeper to the category of each restaurant.\n",
    "\n",
    "\n",
    "# 2.1: Progress continuous - Analysis :\n",
    "**1.**Calculate weighted average scoring for each area to have consistency across each area. Add also one London wide rating to sort areas. Also added one for the 33 boroughs.\n",
    "\n",
    "**2.**Calculate the nearest restaurants average distance as a business classification.Update: the closest KDTree nearby algorithm was used. Extracted the nearest restaurants within a distance of 1km from each restaurant. This will be utilised as a business success rate. It will show probably the exclusivity of each reastaurant in an area.Calculated heactares to sq.km.\n",
    "\n",
    "**3.**Calculate potential average cost of each business/area. Utilising hereditaments-retail by floor space and reting value of £.\n",
    "\n",
    "**4.**Take a look of demographics. Potential PCA to find the most correlated demographics.Inserted the demographics and did the data wranlging before inserting to main database. Main data were focused on age-population-income. In order that data can be analysed. The restaurants dtabase will be grouped by area. One potential column will be the count of business total while the others will be average score ratings. \n",
    "<img src=\"files/Loac_map.jpg\">\n",
    "\n",
    "\n",
    "**Update** For the potential demographics another aproach was selected. The London output area classification was used. This was connected spatially on the clean db . The loac is comprised from smaller areas where census was analysed and categorised into general groups to the demographic characteristics. \n",
    "\n",
    "Currently two files were implemented. The analysis will take place for 2 geolocations. On a bourough and ward level. The Ward level appears the most appropriate since the initial db dowload and classification was based on the ward level.\n",
    "\n",
    "Some initial analysis took place to investigate potential patternss. It seems that more affluent demographics are more active on yelp while other are not. Furthemore, the more affluent categories appear to have a preference towards specific cusisines while more urban demographics towards fast food. \n",
    "The initial investigation took place utilising V-Analytics and connecting two layers of shapefiles. One LOAC shapefile and a converted to WGS ccordinates shapefile with our database. For the conversions the QGIS tool wwas utilised due to the fact it is open source and many more tools that other availiable GIS software.\n",
    "\n",
    "**5.**Potential categories as suggestions to the restaurant to open. The categories were seperated from the Json file and only the initial alias and tile was kept since it a categorisation genral classification.\n",
    "\n",
    "**6.**Potentially find out the population per 1km in each borough and find out the potential clientele. 1km is the radius. So 2km should be the diameter to search. The London Data shapefile will be utilised for this excercise.\n",
    "\n",
    "**Databases connected so far:**\n",
    "https://data.london.gov.uk/dataset/business-demographics-and-survival-rates-borough - For business survival rate\n",
    "https://data.london.gov.uk/dataset/london-area-classification - For demographics and look up values of boroughs LSOA etc.\n",
    "https://data.london.gov.uk/dataset/london-borough-profiles - On seperate file with various census attributes\n",
    "https://data.london.gov.uk/dataset/ward-profiles-and-atlas - On seperate file with characteristics\n",
    "https://data.london.gov.uk/dataset/average-house-prices-ward-lsoa-msoa - Calculated average house prices change rate for the last 5 years.\n",
    "https://data.cdrc.ac.uk/dataset/small-area-population-change-2011-14 - Small area population change. Insterted population of 2011 and 2014 and the change rate.\n",
    "https://data.london.gov.uk/dataset/commercial-and-industrial-floorspace-borough - For floorspace value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Part-4: Python code for initial investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code dowload the Yelp db business rating, number of reviews and details.\n",
    "#The method utilised was based on geospatial location since yelp restricts the total offset number and the location is inclomplete for some cases.\n",
    "#Thus each London area was modifies on ArcGis and centroids were calculated.\n",
    "#Then each shape/area was enclosed in a rectangle and the sides size were calculated.\n",
    "#Then in another code we utilised pythagoreum to calculate diameter and radius of each search parameter/area.\n",
    "#Then we used those centroids cartesian coordinates along with radius to search for the businesses on Yelp.\n",
    "\n",
    "#Import the required libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "%matplotlib inline\n",
    "#Import csv file to export the data\n",
    "final=pd.read_csv('final.csv')\n",
    "#Import csv file with the centroids and radius to call\n",
    "sp=pd.read_csv('Search.csv')\n",
    "#This for loop loops through each London area and returns the Longtitude,Latitude and radius of each area\n",
    "for index,row in sp.iterrows() :\n",
    "    Lat=row.Lat\n",
    "    Long=row.Long\n",
    "    Radius=row.Radius\n",
    "    i=-20\n",
    "    check=pd.read_csv('check.csv')\n",
    "#This while statement ensures that the offset parameter is below the limit specified by Yelp.\n",
    "#If i counter goes above it will return error message\n",
    "    while i<1000: \n",
    "        i+=20\n",
    "#This statement is used to check if we get consecutive blank responses which means there are no more restaurants in the area.\n",
    "#At the moment this allows 2 blank responses before it break the while loop.\n",
    "#It checks the difference between response theoritical count to actual count.\n",
    "        if i-len(check)>80:\n",
    "            break\n",
    "        else:\n",
    "#These are the parameters and the link to call the yelp api\n",
    "#The long,radius and lat parameters change for each area\n",
    "            url = 'https://api.yelp.com/v3/businesses/search'\n",
    "            headers = {'Authorization': 'Bearer ...'}\n",
    "        #The download key was replaced with dots on the line above since Yelp forbids sharing the download key.\n",
    "            params = {'term': 'restaurants',\n",
    "                      'latitude': Lat,\n",
    "                      'longitude': Long,\n",
    "                      'radius': int(Radius),\n",
    "                      'sort_by': 'rating',\n",
    "                      'offset': i\n",
    "                      }\n",
    "#This is where the code send the request to yelp api.\n",
    "            resp = requests.get(url=url, params=params, headers=headers)\n",
    "            print(i)\n",
    "#The server sends blank responses or error so this is where we examine the response and either continue or loop.\n",
    "            try:\n",
    "                tomove=json_normalize(resp.json()['businesses'])\n",
    "            except (IndexError,KeyError,ValueError):\n",
    "                continue\n",
    "            pass\n",
    "#Then the file is consolidated into final df after it is normalised from Json response to pandas df.     \n",
    "            tomove=json_normalize(resp.json()['businesses'])\n",
    "            check=pd.concat([check,tomove])\n",
    "            final=pd.concat([final,tomove])\n",
    "#Timedelay to keep the connection to Yelp live.\n",
    "            time.sleep(1)\n",
    "#Print statements to keep track of progress.\n",
    "    print (row.NAME)\n",
    "    print (len(final))\n",
    "#Final export to csv file.\n",
    "final.to_csv('final.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example yelp API response output received as json from the above code:\n",
    "{\n",
    "  \"businesses\": [\n",
    "    {\n",
    "      \"distance\": 204.04474242560002,\n",
    "      \"categories\": [\n",
    "        {\n",
    "          \"alias\": \"british\",\n",
    "          \"title\": \"British\"\n",
    "        }\n",
    "      ],\n",
    "      \"id\": \"monkey-puzzle-beefeater-grill-chessington-2\",\n",
    "      \"coordinates\": {\n",
    "        \"longitude\": -0.314794,\n",
    "        \"latitude\": 51.348614\n",
    "      },\n",
    "      \"review_count\": 3,\n",
    "      \"is_closed\": false,\n",
    "      \"rating\": 3.5,\n",
    "      \"price\": \"£££\",\n",
    "      \"image_url\": \"https://s3-media1.fl.yelpcdn.com/bphoto/39Kc8B08MYy9CeG3uPN59A/o.jpg\",\n",
    "      \"name\": \"Monkey Puzzle - Beefeater Grill\",\n",
    "      \"url\": \"https://www.yelp.com/biz/monkey-puzzle-beefeater-grill-chessington-2?adjust_creative=xH5CGfNd6xR3i93Wy2f1NQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=xH5CGfNd6xR3i93Wy2f1NQ\",\n",
    "      \"phone\": \"+441372744060\",\n",
    "      \"location\": {\n",
    "        \"country\": \"GB\",\n",
    "        \"address3\": \"\",\n",
    "        \"address2\": \"\",\n",
    "        \"zip_code\": \"KT9 2NE\",\n",
    "        \"state\": \"XGL\",\n",
    "        \"city\": \"Chessington\",\n",
    "        \"address1\": \"Leatherhead Road\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"distance\": 3020.064269504,\n",
    "      \"categories\": [\n",
    "        {\n",
    "          \"alias\": \"indpak\",\n",
    "          \"title\": \"Indian\"\n",
    "        }\n",
    "      ],\n",
    "      \"id\": \"saffron-summer-chessington\",\n",
    "      \"coordinates\": {\n",
    "        \"longitude\": -0.303641147911549,\n",
    "        \"latitude\": 51.3746150604097\n",
    "      },\n",
    "      \"review_count\": 2,\n",
    "      \"is_closed\": false,\n",
    "      \"rating\": 4.5,\n",
    "      \"image_url\": \"https://s3-media2.fl.yelpcdn.com/bphoto/s2rJPBd0W5vCMbPfAu6UUg/o.jpg\",\n",
    "      \"name\": \"Saffron Summer\",\n",
    "      \"url\": \"https://www.yelp.com/biz/saffron-summer-chessington?adjust_creative=xH5CGfNd6xR3i93Wy2f1NQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=xH5CGfNd6xR3i93Wy2f1NQ\",\n",
    "      \"phone\": \"+442083914477\",\n",
    "      \"location\": {\n",
    "        \"country\": \"GB\",\n",
    "        \"address3\": null,\n",
    "        \"address2\": \"Hook Road\",\n",
    "        \"zip_code\": \"KT9 1DR\",\n",
    "        \"state\": \"SRY\",\n",
    "        \"city\": \"Chessington\",\n",
    "        \"address1\": \"4 Ace Parade\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"total\": 34\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>categories</th>\n",
       "      <th>coordinates.latitude</th>\n",
       "      <th>coordinates.longitude</th>\n",
       "      <th>distance</th>\n",
       "      <th>id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>location.address1</th>\n",
       "      <th>...</th>\n",
       "      <th>location.city</th>\n",
       "      <th>location.country</th>\n",
       "      <th>location.state</th>\n",
       "      <th>location.zip_code</th>\n",
       "      <th>name</th>\n",
       "      <th>phone</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'alias': 'historicaltours', 'title': 'Histor...</td>\n",
       "      <td>51.493152</td>\n",
       "      <td>-0.146384</td>\n",
       "      <td>19813.680700</td>\n",
       "      <td>golden-tours-london-2</td>\n",
       "      <td>https://s3-media2.fl.yelpcdn.com/bphoto/bjPk5r...</td>\n",
       "      <td>False</td>\n",
       "      <td>4 Fountain Square</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>GB</td>\n",
       "      <td>XGL</td>\n",
       "      <td>SW1W 9SH</td>\n",
       "      <td>Golden Tours</td>\n",
       "      <td>4.420720e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>101</td>\n",
       "      <td>https://www.yelp.com/biz/golden-tours-london-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'alias': 'indpak', 'title': 'Indian'}]</td>\n",
       "      <td>51.374615</td>\n",
       "      <td>-0.303641</td>\n",
       "      <td>3020.064270</td>\n",
       "      <td>saffron-summer-chessington</td>\n",
       "      <td>https://s3-media2.fl.yelpcdn.com/bphoto/s2rJPB...</td>\n",
       "      <td>False</td>\n",
       "      <td>4 Ace Parade</td>\n",
       "      <td>...</td>\n",
       "      <td>Chessington</td>\n",
       "      <td>GB</td>\n",
       "      <td>SRY</td>\n",
       "      <td>KT9 1DR</td>\n",
       "      <td>Saffron Summer</td>\n",
       "      <td>4.420840e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.yelp.com/biz/saffron-summer-chessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'alias': 'indpak', 'title': 'Indian'}]</td>\n",
       "      <td>51.310281</td>\n",
       "      <td>-0.298107</td>\n",
       "      <td>4300.745498</td>\n",
       "      <td>joy-ashtead-ashtead</td>\n",
       "      <td>https://s3-media4.fl.yelpcdn.com/bphoto/_-U2QV...</td>\n",
       "      <td>False</td>\n",
       "      <td>61AThe Street</td>\n",
       "      <td>...</td>\n",
       "      <td>Ashtead</td>\n",
       "      <td>GB</td>\n",
       "      <td>SRY</td>\n",
       "      <td>KT21 1AA</td>\n",
       "      <td>Joy Ashtead</td>\n",
       "      <td>4.413720e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.yelp.com/biz/joy-ashtead-ashtead?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'alias': 'indpak', 'title': 'Indian'}, {'ali...</td>\n",
       "      <td>51.316812</td>\n",
       "      <td>-0.304217</td>\n",
       "      <td>3506.601226</td>\n",
       "      <td>mogul-dynasty-ashtead</td>\n",
       "      <td>https://s3-media4.fl.yelpcdn.com/bphoto/SYwz9M...</td>\n",
       "      <td>False</td>\n",
       "      <td>1 Craddocks Parade</td>\n",
       "      <td>...</td>\n",
       "      <td>Ashtead</td>\n",
       "      <td>GB</td>\n",
       "      <td>SRY</td>\n",
       "      <td>KT21 1QL</td>\n",
       "      <td>Mogul Dynasty</td>\n",
       "      <td>4.413720e+11</td>\n",
       "      <td>??</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.yelp.com/biz/mogul-dynasty-ashtead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'alias': 'diners', 'title': 'Diners'}]</td>\n",
       "      <td>51.310200</td>\n",
       "      <td>-0.300592</td>\n",
       "      <td>4275.387611</td>\n",
       "      <td>superfish-ashtead-surrey-ashtead</td>\n",
       "      <td>https://s3-media2.fl.yelpcdn.com/bphoto/gNN3V7...</td>\n",
       "      <td>False</td>\n",
       "      <td>2 Woodfield Lane</td>\n",
       "      <td>...</td>\n",
       "      <td>Ashtead</td>\n",
       "      <td>GB</td>\n",
       "      <td>SRY</td>\n",
       "      <td>KT21 2BG</td>\n",
       "      <td>Superfish Ashtead Surrey</td>\n",
       "      <td>4.413720e+11</td>\n",
       "      <td>??</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.yelp.com/biz/superfish-ashtead-sur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0           NaN   \n",
       "1           1           NaN   \n",
       "2           2           NaN   \n",
       "3           3           NaN   \n",
       "4           4           NaN   \n",
       "\n",
       "                                          categories  coordinates.latitude  \\\n",
       "0  [{'alias': 'historicaltours', 'title': 'Histor...             51.493152   \n",
       "1           [{'alias': 'indpak', 'title': 'Indian'}]             51.374615   \n",
       "2           [{'alias': 'indpak', 'title': 'Indian'}]             51.310281   \n",
       "3  [{'alias': 'indpak', 'title': 'Indian'}, {'ali...             51.316812   \n",
       "4           [{'alias': 'diners', 'title': 'Diners'}]             51.310200   \n",
       "\n",
       "   coordinates.longitude      distance                                id  \\\n",
       "0              -0.146384  19813.680700             golden-tours-london-2   \n",
       "1              -0.303641   3020.064270        saffron-summer-chessington   \n",
       "2              -0.298107   4300.745498               joy-ashtead-ashtead   \n",
       "3              -0.304217   3506.601226             mogul-dynasty-ashtead   \n",
       "4              -0.300592   4275.387611  superfish-ashtead-surrey-ashtead   \n",
       "\n",
       "                                           image_url is_closed  \\\n",
       "0  https://s3-media2.fl.yelpcdn.com/bphoto/bjPk5r...     False   \n",
       "1  https://s3-media2.fl.yelpcdn.com/bphoto/s2rJPB...     False   \n",
       "2  https://s3-media4.fl.yelpcdn.com/bphoto/_-U2QV...     False   \n",
       "3  https://s3-media4.fl.yelpcdn.com/bphoto/SYwz9M...     False   \n",
       "4  https://s3-media2.fl.yelpcdn.com/bphoto/gNN3V7...     False   \n",
       "\n",
       "    location.address1                        ...                          \\\n",
       "0   4 Fountain Square                        ...                           \n",
       "1        4 Ace Parade                        ...                           \n",
       "2       61AThe Street                        ...                           \n",
       "3  1 Craddocks Parade                        ...                           \n",
       "4    2 Woodfield Lane                        ...                           \n",
       "\n",
       "  location.city location.country location.state location.zip_code  \\\n",
       "0        London               GB            XGL          SW1W 9SH   \n",
       "1   Chessington               GB            SRY           KT9 1DR   \n",
       "2       Ashtead               GB            SRY          KT21 1AA   \n",
       "3       Ashtead               GB            SRY          KT21 1QL   \n",
       "4       Ashtead               GB            SRY          KT21 2BG   \n",
       "\n",
       "                       name         phone price  rating review_count  \\\n",
       "0              Golden Tours  4.420720e+11   NaN     2.5          101   \n",
       "1            Saffron Summer  4.420840e+11   NaN     4.5            2   \n",
       "2               Joy Ashtead  4.413720e+11   NaN     4.5            2   \n",
       "3             Mogul Dynasty  4.413720e+11    ??     4.5            4   \n",
       "4  Superfish Ashtead Surrey  4.413720e+11    ??     3.0            4   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.yelp.com/biz/golden-tours-london-2...  \n",
       "1  https://www.yelp.com/biz/saffron-summer-chessi...  \n",
       "2  https://www.yelp.com/biz/joy-ashtead-ashtead?a...  \n",
       "3  https://www.yelp.com/biz/mogul-dynasty-ashtead...  \n",
       "4  https://www.yelp.com/biz/superfish-ashtead-sur...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display the final output of the exract from json to panda df:\n",
    "restaurants=pd.read_csv('final.csv')\n",
    "display(restaurants.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code calculates the radius required utilising pythagoreum theorem.\n",
    "#The centroids and the\n",
    "#Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Read the database with Pandas\n",
    "London_Wards=pd.read_csv('London_Wards.csv')\n",
    "#Calculate square of length and width of each rectangle\n",
    "sq_length=London_Wards['Length']**2\n",
    "sq_width=London_Wards['Width']**2\n",
    "#Calculate sum of squares\n",
    "sum=sq_length+sq_width\n",
    "#Calculate the diameter of each rectangle with pythagorian theorem\n",
    "diameter=sum.apply(np.sqrt)\n",
    "#Calculate radius for search parameter\n",
    "radius=diameter/2\n",
    "#Add to London_Wards df\n",
    "London_Wards['Diameter']=diameter\n",
    "London_Wards['Radius']=radius\n",
    "#Export to csv file\n",
    "London_Wards.to_csv('Search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ORIG_FID</th>\n",
       "      <th>OBJECTID *</th>\n",
       "      <th>NAME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>Chislehurst</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>0.074292</td>\n",
       "      <td>51.413093</td>\n",
       "      <td>5185.785850</td>\n",
       "      <td>3180.311784</td>\n",
       "      <td>6083.318003</td>\n",
       "      <td>3042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>Mottingham and Chislehurst North</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>0.041592</td>\n",
       "      <td>51.432307</td>\n",
       "      <td>3214.905141</td>\n",
       "      <td>1182.175015</td>\n",
       "      <td>3425.369007</td>\n",
       "      <td>1713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>Orpington</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>0.109417</td>\n",
       "      <td>51.371321</td>\n",
       "      <td>2349.880482</td>\n",
       "      <td>2269.889626</td>\n",
       "      <td>3267.160418</td>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>Cray Valley West</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>0.102653</td>\n",
       "      <td>51.400349</td>\n",
       "      <td>3556.168188</td>\n",
       "      <td>2054.446892</td>\n",
       "      <td>4106.955589</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>Cray Valley East</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>0.131661</td>\n",
       "      <td>51.391668</td>\n",
       "      <td>4575.797397</td>\n",
       "      <td>4430.149927</td>\n",
       "      <td>6368.999152</td>\n",
       "      <td>3184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ORIG_FID  OBJECTID *                              NAME  \\\n",
       "0          57        57          58                       Chislehurst   \n",
       "1          58        58          59  Mottingham and Chislehurst North   \n",
       "2          59        59          60                         Orpington   \n",
       "3          60        60          61                  Cray Valley West   \n",
       "4          61        61          62                  Cray Valley East   \n",
       "\n",
       "   BOROUGH      Long        Lat       Length        Width     Diameter  Radius  \n",
       "0  Bromley  0.074292  51.413093  5185.785850  3180.311784  6083.318003    3042  \n",
       "1  Bromley  0.041592  51.432307  3214.905141  1182.175015  3425.369007    1713  \n",
       "2  Bromley  0.109417  51.371321  2349.880482  2269.889626  3267.160418    1634  \n",
       "3  Bromley  0.102653  51.400349  3556.168188  2054.446892  4106.955589    2053  \n",
       "4  Bromley  0.131661  51.391668  4575.797397  4430.149927  6368.999152    3184  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Search parameters results after euclidean calculations that will be utilised on the search algorithm on the top cell:\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "search=pd.read_csv('Search.csv')\n",
    "display(search.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45752, 22)\n",
      "(14040, 22)\n",
      "---------------------------------------------------------------------------\n",
      "Unnamed: 0                   0\n",
      "Unnamed: 0.1             14040\n",
      "categories                   0\n",
      "coordinates.latitude        10\n",
      "coordinates.longitude       10\n",
      "distance                     0\n",
      "id                           0\n",
      "image_url                 3985\n",
      "is_closed                    0\n",
      "location.address1           98\n",
      "location.address2         9732\n",
      "location.address3        13628\n",
      "location.city                3\n",
      "location.country             0\n",
      "location.state               0\n",
      "location.zip_code           33\n",
      "name                         0\n",
      "phone                     1197\n",
      "price                     5123\n",
      "rating                       0\n",
      "review_count                 0\n",
      "url                          0\n",
      "dtype: int64\n",
      "---------------------------------------------------------------------------\n",
      "['Unnamed: 0', 'Unnamed: 0.1', 'categories', 'coordinates.latitude', 'coordinates.longitude', 'distance', 'id', 'image_url', 'is_closed', 'location.address1', 'location.address2', 'location.address3', 'location.city', 'location.country', 'location.state', 'location.zip_code', 'name', 'phone', 'price', 'rating', 'review_count', 'url']\n",
      "---------------------------------------------------------------------------\n",
      "categories               100.000000\n",
      "coordinates.latitude      99.928775\n",
      "coordinates.longitude     99.928775\n",
      "distance                 100.000000\n",
      "id                       100.000000\n",
      "image_url                 71.616809\n",
      "is_closed                100.000000\n",
      "location.address1         99.301994\n",
      "location.address2         30.683761\n",
      "location.address3          2.934473\n",
      "location.city             99.978632\n",
      "location.country         100.000000\n",
      "location.state           100.000000\n",
      "location.zip_code         99.764957\n",
      "name                     100.000000\n",
      "phone                     91.474359\n",
      "price                     63.511396\n",
      "rating                   100.000000\n",
      "review_count             100.000000\n",
      "url                      100.000000\n",
      "dtype: float64\n",
      "---------------------------------------------------------------------------\n",
      "count    14040.000000\n",
      "mean         3.585933\n",
      "std          1.160006\n",
      "min          0.000000\n",
      "25%          3.000000\n",
      "50%          4.000000\n",
      "75%          4.500000\n",
      "max          5.000000\n",
      "Name: rating, dtype: float64\n",
      "              \n",
      "count    14040.000000\n",
      "mean         9.967521\n",
      "std         26.979058\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          3.000000\n",
      "75%          9.000000\n",
      "max       1105.000000\n",
      "Name: review_count, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hom49214\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Initial investigation on the data downloaded\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#Import the final downlod file\n",
    "df=pd.read_csv('final.csv')\n",
    "#Print the total shape\n",
    "print(df.shape)\n",
    "#Drop the duplicates to a clean dataframe based on unique urls\n",
    "clean_db=df.drop_duplicates('url')\n",
    "#Print the total rows of the clean dataframe\n",
    "print(clean_db.shape)\n",
    "print('---------------------------------------------------------------------------')\n",
    "#Print the total empty rows\n",
    "print(clean_db.isnull().sum())\n",
    "print('---------------------------------------------------------------------------')\n",
    "#List the columns in order to find unwanted index columns\n",
    "col=list(clean_db.columns.values)\n",
    "print(col)\n",
    "print('---------------------------------------------------------------------------')\n",
    "#Drop the first indexed columns\n",
    "clean_db.drop(clean_db.columns[[0,1]],axis=1,inplace=True)\n",
    "#Calculate the proportion of empty rows to total rows\n",
    "proportion_of_col=(clean_db.count()/len(clean_db.index))*100\n",
    "print(proportion_of_col)\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(clean_db['rating'].describe())\n",
    "print('              ')\n",
    "print(clean_db['review_count'].describe())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
